# AcaRead-Academic-Paper-Analyzer-and-Summarizer
Scholars, students, and other academics must sift through extensive databases of articles, often needing to read and comprehend lengthy abstracts to determine their relevance to their work. This process is time-consuming and can lead to inefficiencies in research progress and information comprehension.
 
We aim to develop a tool that can quickly synthesize and condense key information from academic abstracts, allowing scholars to effectively grasp and utilize research findings without dedicating excessive time to reading each paper in full. We have incorporated various natural language processing techniques to develop our product, including Named-Entity Recognition, Sentiment-Based Search, and Text Summarization using a Large Language Model. Specifically, some of the tools and technologies we used are SpaCy's Named Entity Recognition, sci-kit-learn's TfIdf Vectorizer, BERT's Sentence Embeddings, and a 4bit-quantized Mistral-7B LLM model trained on the Alpaca dataset.

To take a closer look at our methodology, our preprocessing consisted of different methods depending on the function and use of the abstract/query. There was no feature engineering conducted. In some cases, reformatting was conducted to fit sentences on one line. For Named Entity Recognition (NER), the only preprocessing conducted was splitting the abstract by sentences to differentiate better which named entities belonged to which sentence when displaying results. The query was not used. For TfidfVectorizer, we cleaned the abstracts through lowercasing, removing URLs, tokenization, stopword removal, lemmatization, and lowercase the query. For the BERT Sentence Transformer, we cleaned the abstracts by lowercasing, splitting, and removing URLs, and we also lowercase the query.  The textual data from the abstracts are then converted into numerical representations of TfidfVectorizer. After vectorization, we can calculate the Euclidean distances and similarities between our abstracts and the queries we input. We then implemented the BERT Sentence Transformer to convert sentences into high-dimensional vectors. Again, these vectors were compared using Euclidean similarity. Lasty, we incorporated the 4bit-quantized Mistral 7b LLM trained on Yamha’s Alpaca dataset to generate coherent and concise summaries of the abstracts by understanding and paraphrasing the content. No cleaning or pre-processing was conducted before employing the LLM.

Overall, all three of our methods successfully completed their intended task; however, error analysis indicates that our summarizations and BERT sentence embedding distance scores could have been improved. Nevertheless, our sentiment-based search results were still reasonable. As an extension, we intend to account for BERT’s sentence embeddings’ shortcomings with encoding singular words and to evaluate our summaries with LSA or SummTriver to determine quantitative scores without reference summaries.
